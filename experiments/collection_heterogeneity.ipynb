{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 4\n",
    "TOTAL_ROUNDS = 50\n",
    "FRAMES_PER_ROUND = 100 \n",
    "EXPERIMENT_REPEATS = 1\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import torch\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from florl.common.util import aggregate_weighted_average, stateful_client\n",
    "from florl.client.kitten.qt_opt import *\n",
    "\n",
    "from strategy import RlFedAvg\n",
    "from visualisation import *\n",
    "from experiment_utils import *\n",
    "\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "episode_length = FRAMES_PER_ROUND\n",
    "\n",
    "config = DictConfig({\n",
    "    \"rl\": {\n",
    "        \"env\": {\n",
    "            \"name\": \"Pendulum-v1\",\n",
    "            \"max_episode_steps\": episode_length\n",
    "        },\n",
    "        \"algorithm\": {\n",
    "            \"gamma\": 0.99,\n",
    "            \"tau\": 0.005,\n",
    "            \"lr\": 0.001,\n",
    "            \"update_frequency\": 1,\n",
    "            \"clip_grad_norm\": 1,\n",
    "            \"critic\": {\n",
    "                \"features\": 64\n",
    "            }\n",
    "        },\n",
    "        \"memory\": {\n",
    "            \"type\": \"experience_replay\",\n",
    "            \"capacity\": max(128, TOTAL_ROUNDS * FRAMES_PER_ROUND)\n",
    "        },\n",
    "        \"train\": {\n",
    "            \"initial_collection_size\": episode_length,\n",
    "            \"minibatch_size\": 32\n",
    "        }\n",
    "    },\n",
    "    \"fl\": {\n",
    "        \"train_config\": {\n",
    "            \"frames\": FRAMES_PER_ROUND,\n",
    "        },\n",
    "        \"evaluate_config\": {\n",
    "            \"evaluation_repeats\": 1\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "train_config = OmegaConf.to_container(config[\"fl\"][\"train_config\"])\n",
    "evaluate_config = OmegaConf.to_container(config[\"fl\"][\"evaluate_config\"])\n",
    "\n",
    "def _on_fit_config_fn(server_round: int):\n",
    "        return train_config | {\"server_round\": server_round}\n",
    "def _on_evaluate_config_fn(server_round: int):\n",
    "    return evaluate_config | {\"server_round\": server_round}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from flwr.common import Config\n",
    "\n",
    "\n",
    "class MemoryClientFactory(QTOptClientFactory):\n",
    "        def create_client(self, cid: str, config: Config, **kwargs) -> MemoryClient:\n",
    "            client =  super().create_client(cid, config, **kwargs)\n",
    "            return MemoryClient(client)\n",
    "\n",
    "client_factory = MemoryClientFactory(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_WS = \"florl_ws\"\n",
    "\n",
    "evaluation_client = client_factory.create_client(0, config[\"rl\"])._client\n",
    "strategy = RlFedAvg(\n",
    "    knowledge=copy.deepcopy(client_factory.create_default_knowledge(config=config[\"rl\"])),\n",
    "    on_fit_config_fn = _on_fit_config_fn,\n",
    "    on_evaluate_config_fn= _on_evaluate_config_fn,\n",
    "    fit_metrics_aggregation_fn=aggregate_weighted_average,\n",
    "    evaluate_metrics_aggregation_fn=aggregate_weighted_average,\n",
    "    evaluate_fn=get_evaluation_fn(evaluation_client),\n",
    "    accept_failures=False,\n",
    "    inplace=False\n",
    ")\n",
    "\n",
    "federated_results = []\n",
    "rng = np.random.default_rng(seed=SEED)\n",
    "\n",
    "for _ in tqdm(range(EXPERIMENT_REPEATS)):\n",
    "    seed = rng.integers(0, 65535)\n",
    "    if os.path.exists(CONTEXT_WS):\n",
    "        shutil.rmtree(CONTEXT_WS)\n",
    "\n",
    "    @stateful_client\n",
    "    def build_client(cid: str) -> fl.client.Client:\n",
    "        cid = int(cid) + seed\n",
    "        return client_factory.create_client(\n",
    "            cid=cid,\n",
    "            config=config[\"rl\"],\n",
    "            enable_evaluation = False\n",
    "        )\n",
    "\n",
    "    hist = fl.simulation.start_simulation(\n",
    "        client_fn=build_client,\n",
    "        client_resources={'num_cpus': 1},\n",
    "        config=fl.server.ServerConfig(num_rounds=TOTAL_ROUNDS),\n",
    "        num_clients = NUM_CLIENTS,\n",
    "        strategy = strategy\n",
    "    )\n",
    "\n",
    "    federated_results.append(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Analysis functions\n",
    "\n",
    "def pendulum_dimensionality_reduction(states: torch.Tensor):\n",
    "    # X: sin(theta)\n",
    "    x = torch.atan2(states[:,0], states[:, 1]).sin()\n",
    "    # Y: Min-max\n",
    "    y = states[:, 2] / 8.0\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def kld(p: np.ndarray, q: np.ndarray, k: int = 5):\n",
    "    \"\"\" Estimates D(p||q)\n",
    "\n",
    "    Implements\n",
    "    Wang et al. Divergence Estimation for Multidimensional Densities Via Nearest-Neighbor Distances\n",
    "\n",
    "    In bits. Distance is Euclidean.\n",
    "\n",
    "    Args:\n",
    "        p (np.ndarray): Samples from the true distribution.\n",
    "        q (np.ndarray): Samples from the encoding distribution.\n",
    "    \"\"\"\n",
    "    N, M = len(p), len(q)\n",
    "    result = 0\n",
    "\n",
    "    # Fit Nearest Neighbors\n",
    "    nn_p = NearestNeighbors(n_neighbors=k).fit(p)\n",
    "    nn_q = NearestNeighbors(n_neighbors=k).fit(q)\n",
    "    # Calculate the distance to the k nearest neighbor\n",
    "    distances_e, _ = nn_p.kneighbors(p)\n",
    "    distances_v, _ = nn_q.kneighbors(p)\n",
    "    distances_e = distances_e[:, -1]\n",
    "    distances_v = distances_v[:, -1]\n",
    "    # Summation\n",
    "    result += np.log2(distances_v / distances_e).sum()\n",
    "    # Final logarithmic term\n",
    "    result = result * (len(p[0]) / N)\n",
    "    result += np.log2(M/(N-1))\n",
    "    return result\n",
    "\n",
    "\n",
    "def jsd(batch_1: torch.Tensor, batch_2: torch.Tensor, k: int = 5):\n",
    "    \"\"\" Estimates the Jensen-Shannon divergence between distributions whose samples form batch_1 and batch_2\n",
    "    \n",
    "    Args:\n",
    "        batch_1 (torch.Tensor): Samples from the first distribution.\n",
    "        batch_2 (torch.Tensor): Samples from the second distribution.\n",
    "    \"\"\"\n",
    "    batch_1, batch_2 = np.array(batch_1), np.array(batch_2)\n",
    "    return (kld(batch_1, batch_2, k) + kld(batch_2, batch_1, k)) / 2\n",
    "\n",
    "\n",
    "# Plotting\n",
    "N_COL = 6\n",
    "N_ROW = 3\n",
    "\n",
    "sns.set_theme()\n",
    "fig, axs = plt.subplots(N_ROW, N_COL, sharey='row',  gridspec_kw={'hspace': 0.2, 'wspace': 0.1})\n",
    "fig.set_size_inches(N_COL * 4, N_ROW * 4)\n",
    "\n",
    "fig.suptitle(\"Replay Buffer Heterogeneity\")\n",
    "colors = sns.color_palette(\"husl\", NUM_CLIENTS)\n",
    "markers = [\"o\", \"s\", \"P\", \"^\", \"X\"]\n",
    "\n",
    "# Text annotations for each row\n",
    "fig.text(0.04, 0.77, \"All, Replay Buffer\", ha='center', va='center', rotation='vertical', fontsize=12)\n",
    "fig.text(0.04, 0.5, \"Latest Episode, Replay Buffer\", ha='center', va='center', rotation='vertical', fontsize=12)\n",
    "fig.text(0.04, 0.23, \"All, Divergence\", ha='center', va='center', rotation='vertical', fontsize=12)\n",
    "\n",
    "ids_ = federated_results[0].metrics_distributed_fit[\"id\"]\n",
    "id_to_index = {id_: i  for i, id_ in enumerate([x[1] for x in ids_[0][1][\"all\"]])}\n",
    "\n",
    "\n",
    "# Precompute divergence maps\n",
    "divergence_matrices = [None for _ in range(N_COL)]\n",
    "for i in range(N_COL):\n",
    "    round_number =  min(TOTAL_ROUNDS-1, int(TOTAL_ROUNDS * (i/(N_COL-1)) + (i/(N_COL-1)) // 2))\n",
    "    transition_states_clients = [pickle.loads(x) for x in federated_results[0].metrics_distributed_fit['rb'][round_number][1]]\n",
    "    order = [(j, id_to_index[ids_[round_number][1][\"all\"][j][1]]) for j in range(len(transition_states_clients))]\n",
    "    order.sort(key=lambda x: x[1])\n",
    "    n = int(federated_results[0].metrics_distributed_fit[\"rb_size\"][round_number][1]['avg'])\n",
    "    divergence_matrix = np.zeros((NUM_CLIENTS, NUM_CLIENTS))\n",
    "    for j, _ in order:\n",
    "        for k, _ in order:\n",
    "            if k == j:\n",
    "                continue\n",
    "            data_j = transition_states_clients[j][:n]\n",
    "            id_j = ids_[round_number][1][\"all\"][j][1]\n",
    "            index_j = id_to_index[id_j]\n",
    "            data_k = transition_states_clients[k][:n]\n",
    "            id_k = ids_[round_number][1][\"all\"][k][1]\n",
    "            index_k = id_to_index[id_k]\n",
    "            divergence_matrix[index_j, index_k] = jsd(data_j, data_k)\n",
    "    divergence_matrices[i] = divergence_matrix\n",
    "maximum_divergence = max([x.max() for x in divergence_matrices])\n",
    "minimum_divergence = min([x.min() for x in divergence_matrices])\n",
    "\n",
    "for i in range(N_COL):\n",
    "    round_number =  min(TOTAL_ROUNDS-1, int(TOTAL_ROUNDS * (i/(N_COL-1)) + (i/(N_COL-1)) // 2))\n",
    "    transition_states_clients = [pickle.loads(x) for x in federated_results[0].metrics_distributed_fit['rb'][round_number][1]]\n",
    "    new_transition_states_clients = [pickle.loads(x) for x in federated_results[0].metrics_distributed_fit['rb_new'][round_number][1]]\n",
    "    \n",
    "    # Total\n",
    "    ax = axs[0][i]\n",
    "    ax.set_title(f\"Round {round_number}\")\n",
    "\n",
    "    order = [(j, id_to_index[ids_[round_number][1][\"all\"][j][1]]) for j in range(len(transition_states_clients))]\n",
    "    order.sort(key=lambda x: x[1])\n",
    "\n",
    "    n = int(federated_results[0].metrics_distributed_fit[\"rb_size\"][round_number][1]['avg'])\n",
    "    for j, _ in order:\n",
    "        data = transition_states_clients[j]\n",
    "        id_ = ids_[round_number][1][\"all\"][j][1]\n",
    "        index = id_to_index[id_]\n",
    "        x, y = pendulum_dimensionality_reduction(data[:n])\n",
    "        ax.scatter(x, y, color=colors[index], s=5, marker=markers[index], label=f\"Client {index}\")\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(-1, 1)\n",
    "\n",
    "    # New\n",
    "    ax = axs[1][i]\n",
    "    for j, data in enumerate(new_transition_states_clients):\n",
    "        id_ = ids_[round_number][1][\"all\"][j][1]\n",
    "        index = id_to_index[id_]\n",
    "        x, y = pendulum_dimensionality_reduction(data)\n",
    "        ax.scatter(x, y, color=colors[index], s=5, marker=markers[index], label=f\"Client {index}\")\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(-1, 1)\n",
    "\n",
    "    # Similarity Matrix\n",
    "    ax = axs[2][i]\n",
    "    #sns.heatmap(divergence_matrices[i], ax=ax, vmax=maximum_divergence, vmin=minimum_divergence, cbar=True)\n",
    "    sns.heatmap(divergence_matrices[i], ax=ax, cbar=True, annot=True)\n",
    "\n",
    "for ax in axs.flat:# Analysis functions\n",
    "    ax.label_outer()\n",
    "for i in range(2):\n",
    "    axs[i][0].set_ylabel(\"CCW Torque (Normalised)\")\n",
    "for j in range(N_COL):\n",
    "    axs[0][j].set_xlabel('Sin(θ)')\n",
    "    axs[1][j].set_xlabel('Sin(θ)')\n",
    "\n",
    "handles, labels = axs[-2, -1].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=NUM_CLIENTS, title=\"Clients\", fontsize='small', title_fontsize='medium', markerscale=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
